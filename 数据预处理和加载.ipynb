{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch数据读入是通过Dataset+DataLoader的方式完成的，Dataset定义好数据的格式和数据变换形式，DataLoader用iterative的方式不断读入批次数据。"
      ],
      "metadata": {
        "id": "BH-_vkD13jzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "ihPGvX872-zq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "自定义一个继承 Dataset类的类 ，需要重写以下三个函数：\n",
        "\n",
        "__init__：传入数据，或者像下面一样直接在函数里加载数据；\n",
        "\n",
        "__len__：返回这个数据集一共有多少个item；\n",
        "\n",
        "__getitem__:返回一条训练数据，并将其转换成tensor。\n",
        "\n",
        "通常还会在其中增加一个collate_fn函数，用于DataLoader，使用这个参数可以自己操作每个batch的数据，比如说在自然语言处理的命名实体识别任务中，在该函数中对每个batch中的样本都padding到同一长度等。"
      ],
      "metadata": {
        "id": "O0kH-01a26yE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SquareDataset(Dataset):\n",
        "    def __init__(self, numbers, transform=None):\n",
        "        self.numbers = numbers\n",
        "        self.labels = [x**2 for x in numbers]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.numbers)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.numbers[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        return sample, label\n",
        "\n",
        "# 创建数据集\n",
        "numbers = [1, 2, 3, 4, 5]\n",
        "dataset = SquareDataset(numbers)\n",
        "\n",
        "# 使用 DataLoader 加载数据\n",
        "from torch.utils.data import DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "# 遍历 DataLoader\n",
        "for batch in dataloader:\n",
        "    print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDpqKwl5kpev",
        "outputId": "054ea682-258e-4d4a-fd23-383260009243"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([1, 2]), tensor([1, 4])]\n",
            "[tensor([5, 3]), tensor([25,  9])]\n",
            "[tensor([4]), tensor([16])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "transform 是一个可选参数，通常用于对数据进行预处理或增强。你可以使用 PyTorch 提供的 torchvision.transforms 模块中的函数，或者自定义转换函数。"
      ],
      "metadata": {
        "id": "QjZdXtKImDjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "dataset = SquareDataset(numbers, transform=transform)"
      ],
      "metadata": {
        "id": "EdU0UPLYmFke"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TensorDataset"
      ],
      "metadata": {
        "id": "3UD0LZY620Qp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.utils.data.TensorDataset 是 PyTorch 提供的一个便捷类，用于将多个张量（Tensor）组合成一个数据集。它继承自 torch.utils.data.Dataset，并自动实现了 ___len__ 和 ___getitem__ 方法，因此你无需手动实现这些方法。\n",
        "\n",
        "TensorDataset 的主要用途是将输入数据和标签数据（或其他相关数据）打包成一个数据集，方便后续通过 DataLoader 进行批量加载。"
      ],
      "metadata": {
        "id": "Z2RWELAzoIyY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwYpd1-Wm7Q6",
        "outputId": "237a39fe-3f3c-4e14-9046-07e733a27b93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "(tensor([1., 2.]), tensor(0.))\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# 创建输入数据和标签\n",
        "X = torch.tensor([[1, 2], [3, 4], [5, 6]], dtype=torch.float32)  # 3个样本，每个样本2个特征\n",
        "y = torch.tensor([0, 1, 0], dtype=torch.float32)  # 3个标签\n",
        "\n",
        "# 创建 TensorDataset\n",
        "dataset = TensorDataset(X, y)\n",
        "\n",
        "# 查看数据集大小\n",
        "print(len(dataset))  # 输出: 3\n",
        "\n",
        "# 获取单个样本\n",
        "print(dataset[0])  # 输出: (tensor([1., 2.]), tensor(0.))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorDataset 通常与 DataLoader 结合使用，以便批量加载数据。"
      ],
      "metadata": {
        "id": "zIlr6IE7zbVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 创建 DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "# 遍历 DataLoader4\n",
        "for batch_X, batch_y in dataloader:\n",
        "    print(\"Batch X:\", batch_X)\n",
        "    print(\"Batch y:\", batch_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhUMWIzxnGUh",
        "outputId": "39bead4c-4143-4dfe-866e-59e557f1a8f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch X: tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "Batch y: tensor([0., 1.])\n",
            "Batch X: tensor([[5., 6.]])\n",
            "Batch y: tensor([0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorDataset 可以接受多个张量，例如输入数据、标签数据和其他辅助数据。"
      ],
      "metadata": {
        "id": "h5-Pry_Wz8-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建输入数据、标签和其他辅助数据\n",
        "X = torch.tensor([[1, 2], [3, 4], [5, 6]], dtype=torch.float32)\n",
        "y = torch.tensor([0, 1, 0], dtype=torch.float32)\n",
        "z = torch.tensor([10, 20, 30], dtype=torch.float32)  # 辅助数据\n",
        "\n",
        "# 创建 TensorDataset\n",
        "dataset = TensorDataset(X, y, z)\n",
        "\n",
        "# 获取单个样本\n",
        "print(dataset[1])  # 输出: (tensor([3., 4.]), tensor(1.), tensor(20.))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxWsb_Cxz-vj",
        "outputId": "2f776a88-da32-4b97-86eb-425a3bbd6c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([3., 4.]), tensor(1.), tensor(20.))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Vh8gGs-50sH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader"
      ],
      "metadata": {
        "id": "YoQUcygy0sWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoader包括三个参数：\n",
        "\n",
        "dataset：传入的数据；\n",
        "\n",
        "shuffle = True:是否打乱数据；\n",
        "\n",
        "collate_fn函数：使用这个参数可以自己操作每个batch的数据。\n",
        "\n",
        "drop_last：告诉如何处理划分batch后剩下的最后不足一个batch的样本集合，True就抛弃，否则保留。"
      ],
      "metadata": {
        "id": "CxsHUx7m2m8Y"
      }
    }
  ]
}